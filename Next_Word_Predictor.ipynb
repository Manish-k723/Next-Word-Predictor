{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cz029tT2_xaa"
      },
      "outputs": [],
      "source": [
        "essay = '''TensorFlow: A Versatile Framework for Deep Learning\n",
        "TensorFlow is an open-source machine learning framework developed by the Google Brain team.\n",
        "Renowned for its flexibility and scalability, TensorFlow has become one of the most popular tools for deep learning research and production-level deployment.\n",
        "At its core, TensorFlow offers a computational graph framework that allows developers to define and execute complex machine learning models efficiently.\n",
        "The framework is designed to handle a wide range of tasks, from image and natural language processing to reinforcement learning and more.\n",
        "\n",
        "Usage of TensorFlow: Versatility and Wide Adoption\n",
        "\n",
        "One of TensorFlow's standout features is its versatility. It provides a unified platform for creating and training machine learning models across diverse domains.\n",
        "TensorFlow supports both traditional neural networks and cutting-edge deep learning architectures like convolutional neural networks (CNNs) and recurrent neural networks (RNNs).\n",
        "Furthermore, TensorFlow's ecosystem includes high-level APIs like Keras, which simplifies the process of building and training deep learning models,\n",
        "making it accessible to both beginners and experts.\n",
        "\n",
        "Keras Integration: Streamlined Model Development\n",
        "\n",
        "Keras, a high-level neural networks API, has been tightly integrated into TensorFlow since version 2.0.\n",
        "This integration offers users the best of both worldsâ€”Keras's user-friendly interface and TensorFlow's power and scalability.\n",
        "Keras allows developers to define neural network architectures using a simple and intuitive syntax. It abstracts away many of the low-level details,\n",
        "enabling rapid prototyping and experimentation. By using Keras within TensorFlow, developers can seamlessly transition from model design and training to production deployment.\n",
        "\n",
        "Conclusion: Empowering Innovation in Machine Learning\n",
        "\n",
        "In conclusion, TensorFlow, with its integrated Keras API, empowers developers and researchers in the field of machine learning.\n",
        "Its versatility and wide adoption make it a preferred choice for a variety of applications, from image classification to natural language understanding.\n",
        "Whether you're just starting your journey in deep learning or working on advanced research, TensorFlow's rich ecosystem, coupled with Keras's user-friendly interface,\n",
        "provides the tools and flexibility needed to push the boundaries of innovation in the field of machine learning.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Xm43hwBxDacH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "_Kc4v9QnDbVW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([essay])"
      ],
      "metadata": {
        "id": "L5LTijztFJck"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index) # To see what index has been assigned to each word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeM1eHPyFNot",
        "outputId": "0d86f220-5f14-457b-a641-6f44d7d24214"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "173"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in essay.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    n_gram = tokenized_sentence[:i+1]\n",
        "    input_sequences.append(n_gram)"
      ],
      "metadata": {
        "id": "XXipjy3KFPzd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "bIbXdCalFjj0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen = max_len, padding = 'pre')"
      ],
      "metadata": {
        "id": "_sYCnw1BJCRE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_sequences[:,:-1]\n",
        "y = padded_sequences[:,-1]"
      ],
      "metadata": {
        "id": "zFwTXd03JYsl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2GQTc-3JzrJ",
        "outputId": "0123240f-62e2-4e7a-a049-a207a5760b16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((318, 22), (318,))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes = 174)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "FTqq9huaR_Z1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Architecture of model: I will be using 3 layers in the NN.\n",
        "#1st layer = Embedding Layer: It will a dense vector\n",
        "#2nd layer = LSTM layer\n",
        "#3rd layer = Dense Layer for output"
      ],
      "metadata": {
        "id": "vmTOw1sdSnUS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "UyM5PM8gTRXz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(174, 100, input_length = 22))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(174, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "Iij6iaWHTWNH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "CzuzcgBEUQXs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzYts47GUcN_",
        "outputId": "d8e78095-1ff8-4995-d7ab-d5d09867a624"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 23, 100)           17400     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               117248    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 174)               22446     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 157094 (613.65 KB)\n",
            "Trainable params: 157094 (613.65 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs = 100)"
      ],
      "metadata": {
        "id": "xO-nOcDOUdHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"what is tensorflow\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_text = pad_sequences([token_text], maxlen = 22, padding = 'pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_text))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "      # print(word)\n",
        "      text = text+' '+word\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKXdXVkcXCBb",
        "outputId": "8f2cd688-ca9b-4d13-dcff-0e4f04bbe1c8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n",
            "what is tensorflow is\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "what is tensorflow is an\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "what is tensorflow is an open\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "what is tensorflow is an open source\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "what is tensorflow is an open source machine\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "what is tensorflow is an open source machine learning\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "what is tensorflow is an open source machine learning framework\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "what is tensorflow is an open source machine learning framework developed\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "what is tensorflow is an open source machine learning framework developed by\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "what is tensorflow is an open source machine learning framework developed by the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(model, open(\"model.pickle\", 'wb'))"
      ],
      "metadata": {
        "id": "JsUhz65mgYbo"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COU6oefIgeca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}